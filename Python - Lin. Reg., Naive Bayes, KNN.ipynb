{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87b2345b-b917-4261-9c3b-0e735ece31bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted  Coefficient\n",
      "0  Intercept   -29.193467\n",
      "1       CRIM    -0.240062\n",
      "2       CHAS     3.266817\n",
      "3         RM     8.325175\n"
     ]
    }
   ],
   "source": [
    "#Question 6.1b\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "house_df = pd.read_csv('BostonHousing.csv')\n",
    "house_df = house_df.iloc[0:1000]\n",
    "predictors = ['CRIM', 'CHAS', 'RM']\n",
    "outcome = 'MEDV'\n",
    "\n",
    "X = pd.get_dummies(house_df[predictors], drop_first=True)\n",
    "y = house_df[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "house_lm = LinearRegression()\n",
    "house_lm.fit(train_X, train_y)\n",
    "\n",
    "print(pd.DataFrame({'Predicted': ['Intercept'] + predictors, 'Coefficient': [house_lm.intercept_] + list(house_lm.coef_)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a4e7fa0-c79a-470b-878b-418fed90b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted median house price: $20733.578132519167\n"
     ]
    }
   ],
   "source": [
    "#Question 6.1c\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "house_df = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "predictors = ['CRIM', 'CHAS', 'RM']\n",
    "response = 'MEDV'\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(house_df[predictors], house_df[response], test_size=0.4, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "data = pd.DataFrame({'CRIM': [0.1], 'CHAS': [0], 'RM': [6]})\n",
    "price = model.predict(data)\n",
    "\n",
    "print(f\"Predicted median house price: ${price[0]*1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99a6071-6b81-4be0-b7c0-a9fd68675cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
      "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO     LSTAT  \n",
      "CRIM    -0.379670  0.625505  0.582764  0.289946  0.455621  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679 -0.412995  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248  0.603800  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515 -0.053929  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933  0.590879  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501 -0.613808  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515  0.602339  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471 -0.496996  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741  0.488676  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853  0.543993  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000  0.374044  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044  1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Question 6.1d(ii)\n",
    "import pandas as pd\n",
    "\n",
    "house_df = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "predictors = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'LSTAT']\n",
    "response = 'MEDV'\n",
    "\n",
    "matrix = house_df[predictors].corr()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140c7f7a-9fdc-4392-aa8d-bd9bf487dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Elimination\n",
      "Variables: INDUS, NOX, RM, TAX, PTRATIO\n",
      "Start: score=1907.87\n",
      "Step: score=1905.87, remove INDUS\n",
      "Step: score=1905.16, remove TAX\n",
      "Step: score=1905.16, remove None\n",
      "['NOX', 'RM', 'PTRATIO']\n",
      "Backward Elimination - RMSE: 6.195415103912311, MAPE: 0.2059143069398552, Mean Error: 0.41950040137259326\n",
      "\n",
      "\n",
      "Forward Elimination\n",
      "Variables: INDUS, NOX, RM, TAX, PTRATIO\n",
      "Start: score=2191.75, constant\n",
      "Step: score=1989.28, add RM\n",
      "Step: score=1938.72, add TAX\n",
      "Step: score=1921.51, add PTRATIO\n",
      "Step: score=1905.87, add NOX\n",
      "Step: score=1905.87, add None\n",
      "['RM', 'TAX', 'PTRATIO', 'NOX']\n",
      "Forward Selection - RMSE: 6.151954158615837, MAPE: 0.20168775708472764, Mean Error: 0.4024606963885238\n",
      "\n",
      "\n",
      "Stepwise Elimination Initial\n",
      "Variables: INDUS, NOX, RM, TAX, PTRATIO\n",
      "Start: score=2191.75, constant\n",
      "Step: score=1989.28, add RM\n",
      "Step: score=1938.72, add TAX\n",
      "Step: score=1921.51, add PTRATIO\n",
      "Step: score=1905.87, add NOX\n",
      "Step: score=1905.16, remove TAX\n",
      "Step: score=1905.16, unchanged None\n",
      "['RM', 'PTRATIO', 'NOX']\n",
      "Stepwise Selection - RMSE: 6.195415103912311, MAPE: 0.2059143069398553, Mean Error: 0.41950040137258987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stepwise Elimination Final\n",
      "Variables: INDUS, NOX, TAX\n",
      "Start: score=2191.75, constant\n",
      "Step: score=2096.15, add INDUS\n",
      "Step: score=2090.93, add TAX\n",
      "Step: score=2088.35, add NOX\n",
      "Step: score=2088.35, unchanged None\n",
      "['INDUS', 'TAX', 'NOX']\n",
      "Stepwise Selection - RMSE: 8.515131003401658, MAPE: 0.2525132755692878, Mean Error: 0.8923224390011274\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Question 6.1d(iii)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "from dmba import regressionSummary, exhaustive_search, backward_elimination, forward_selection, stepwise_selection, adjusted_r2_score, AIC_score, BIC_score\n",
    "\n",
    "house_df = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "predictors = ['INDUS', 'NOX', 'RM', 'TAX', 'PTRATIO']\n",
    "response = 'MEDV'\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(house_df[predictors], house_df[response], test_size=0.4, random_state=1)\n",
    "\n",
    "# Helper\n",
    "def evaluate_model(model, valid_X, valid_y):\n",
    "    predictions = model.predict(valid_X)\n",
    "    residuals = valid_y - predictions\n",
    "    rmse = mean_squared_error(valid_y, predictions, squared=False)\n",
    "    mape = mean_absolute_percentage_error(valid_y, predictions)\n",
    "    mean_error = residuals.mean()\n",
    "    return rmse, mape, mean_error, residuals\n",
    "\n",
    "def plot_histogram(residuals, model_name):\n",
    "    plt.hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Residual Histogram: {model_name}')\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{model_name}_histogram.jpg')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#Backward\n",
    "print(\"Backward Elimination\")\n",
    "def train_model(variables):\n",
    "  model = LinearRegression()\n",
    "  model.fit(train_X[variables], train_y)\n",
    "  return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "  return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "allVariables = train_X.columns\n",
    "best_model, best_variables = backward_elimination(allVariables, train_model, score_model, verbose=True)\n",
    "\n",
    "print(best_variables)\n",
    "rmse_backward, mape_backward, mean_error_backward, residuals_backward = evaluate_model(best_model, valid_X[best_variables], valid_y)\n",
    "print(f\"Backward Elimination - RMSE: {rmse_backward}, MAPE: {mape_backward}, Mean Error: {mean_error_backward}\")\n",
    "plot_histogram(residuals_backward, 'Backward Elimination')\n",
    "print()\n",
    "print()\n",
    "\n",
    "#Forward\n",
    "print(\"Forward Elimination\")\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0: \n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "    \n",
    "best_model, best_variables = forward_selection(train_X.columns, train_model, score_model, verbose=True)\n",
    "print(best_variables)\n",
    "rmse_forward, mape_forward, mean_error_forward, residuals_forward = evaluate_model(best_model, valid_X[best_variables], valid_y)\n",
    "print(f\"Forward Selection - RMSE: {rmse_forward}, MAPE: {mape_forward}, Mean Error: {mean_error_forward}\")\n",
    "plot_histogram(residuals_forward, 'Forward Selection')\n",
    "print()\n",
    "print()\n",
    "\n",
    "#Stepwise\n",
    "print(\"Stepwise Elimination Initial\")\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0: \n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "    \n",
    "best_model, best_variables = stepwise_selection(train_X.columns, train_model, score_model, verbose=True)\n",
    "print(best_variables)\n",
    "rmse_stepwise, mape_stepwise, mean_error_stepwise, residuals_stepwise = evaluate_model(best_model, valid_X[best_variables], valid_y)\n",
    "print(f\"Stepwise Selection - RMSE: {rmse_stepwise}, MAPE: {mape_stepwise}, Mean Error: {mean_error_stepwise}\")\n",
    "plot_histogram(residuals_stepwise, 'Stepwise Selection Initial')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Stepwise Elimination Final\")\n",
    "predictors = ['INDUS', 'NOX', 'TAX']\n",
    "response = 'MEDV'\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(house_df[predictors], house_df[response], test_size=0.4, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0: \n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "    \n",
    "best_model, best_variables = stepwise_selection(train_X.columns, train_model, score_model, verbose=True)\n",
    "print(best_variables)\n",
    "rmse_stepwise, mape_stepwise, mean_error_stepwise, residuals_stepwise = evaluate_model(best_model, valid_X[best_variables], valid_y)\n",
    "print(f\"Stepwise Selection - RMSE: {rmse_stepwise}, MAPE: {mape_stepwise}, Mean Error: {mean_error_stepwise}\")\n",
    "plot_histogram(residuals_stepwise, 'Stepwise Selection Final')\n",
    "print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa78985-f552-4122-b440-09fef00f3af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de73ee51-c38c-4fab-b444-17159eca6226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 3, MSE: 21.82572523262178\n",
      "Predicted MEDV: 18.766666666666666\n"
     ]
    }
   ],
   "source": [
    "#Question 7.3a\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "X = data.drop(columns=[\"MEDV\", \"CAT. MEDV\"])\n",
    "y = data[\"MEDV\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_new = scaler.fit_transform(X_train)\n",
    "X_val_new = scaler.transform(X_val)\n",
    "\n",
    "mse_results = {}\n",
    "for k in range(1, 6):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train_new, y_train)\n",
    "    y_val_pred = knn.predict(X_val_new)\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "    mse_results[k] = mse\n",
    "\n",
    "best_k = min(mse_results, key=mse_results.get)\n",
    "\n",
    "print(f\"Best k: {best_k}, MSE: {mse_results[best_k]}\")\n",
    "\n",
    "new_data_point = pd.DataFrame({\n",
    "    'CRIM': [0.2],\n",
    "    'ZN': [0],\n",
    "    'INDUS': [7],\n",
    "    'CHAS': [0],\n",
    "    'NOX': [0.538],\n",
    "    'RM': [6],\n",
    "    'AGE': [62],\n",
    "    'DIS': [4.7],\n",
    "    'RAD': [4],\n",
    "    'TAX': [307],\n",
    "    'PTRATIO': [21],\n",
    "    'LSTAT': [10]\n",
    "})\n",
    "\n",
    "new_data_point_scaled = scaler.transform(new_data_point)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=best_k)\n",
    "knn.fit(X_train_new, y_train)\n",
    "medv_prediction = knn.predict(new_data_point_scaled)\n",
    "\n",
    "print(f\"Predicted MEDV: {medv_prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3ecac4e-6816-49cc-ba24-699756a0fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  {1: 29.194876847290637, 2: 22.83465517241379, 3: 21.82572523262178, 4: 22.936616379310347, 5: 25.14845123152709}\n",
      "MEDV Prediction, k = 3: $ 18.766666666666666\n",
      "MSE:  11.347334066740007\n"
     ]
    }
   ],
   "source": [
    "#Question 7.3bc\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "mse_results = {}\n",
    "for k in range(1, 6):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_val_pred = knn.predict(X_val_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    " \n",
    "    mse_results[k] = mse\n",
    "\n",
    "#MSE for k = 1 to 5\n",
    "print(\"MSE: \",mse_results)\n",
    "\n",
    "data_scaled = scaler.transform(new_data_point)\n",
    "\n",
    "knn_best = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_best.fit(X_train_scaled, y_train)\n",
    "medv_prediction = knn_best.predict(new_data_point_scaled)\n",
    "\n",
    "print(\"MEDV Prediction, k = 3: $\",medv_prediction[0])\n",
    "\n",
    "y_train_pred = knn_best.predict(X_train_scaled)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"MSE: \",train_mse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa9415-15e5-447f-ad52-d31b895ef603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "92a6606b-e3b3-4a08-9e6f-faf6ff71a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part a:\n",
      "The baseline prediction should be: INJURY = yes\n",
      "\n",
      "Part b(i):\n",
      "INJURY                no  yes\n",
      "WEATHER_R TRAF_CON_R         \n",
      "1         0            1    2\n",
      "          1            1    0\n",
      "          2            1    0\n",
      "2         0            5    1\n",
      "          1            1    0\n",
      "\n",
      "Part b(ii):\n",
      "INJURY                no  yes  P(INJURY = yes)\n",
      "WEATHER_R TRAF_CON_R                          \n",
      "1         0            1    2         0.666667\n",
      "          1            1    0         0.000000\n",
      "          2            1    0         0.000000\n",
      "2         0            5    1         0.166667\n",
      "          1            1    0         0.000000\n",
      "\n",
      "Part b(iii):\n",
      "INJURY                P(INJURY = yes) Prediction\n",
      "WEATHER_R TRAF_CON_R                            \n",
      "1         0                  0.666667        yes\n",
      "          1                  0.000000         no\n",
      "          2                  0.000000         no\n",
      "2         0                  0.166667         no\n",
      "          1                  0.000000         no\n",
      "\n",
      "Part b(iv): 0.0000\n",
      "\n",
      "Part c(ii)):\n",
      "[[5571 2758]\n",
      " [4963 3582]]\n",
      "\n",
      "Part c(iii): Overall error rate for the validation set: 0.46\n",
      "\n",
      "Part c(iv): Naive error rate: 0.49\n",
      "Percent improvement relative to the naive rule: 7.30%\n"
     ]
    }
   ],
   "source": [
    "#Question 8.2abc\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "data = pd.read_csv('accidentsFull.csv')\n",
    "\n",
    "#a\n",
    "data['INJURY'] = data['MAX_SEV_IR'].apply(lambda x: 'yes' if x in [1, 2] else 'no')\n",
    "prediction = data['INJURY'].value_counts().idxmax()\n",
    "print(\"Part a:\")\n",
    "print(f\"The baseline prediction should be: INJURY = {prediction}\")\n",
    "print()\n",
    "\n",
    "\n",
    "#b(i)\n",
    "subset = data[['INJURY', 'WEATHER_R', 'TRAF_CON_R']].head(12)\n",
    "pivot_table = pd.pivot_table(subset, values='INJURY', index=['WEATHER_R', 'TRAF_CON_R'], columns=['INJURY'], aggfunc=len, fill_value=0)\n",
    "print(\"Part b(i):\")\n",
    "print(pivot_table)\n",
    "print()\n",
    "\n",
    "#b(ii)\n",
    "combination_counts = subset.groupby(['WEATHER_R', 'TRAF_CON_R', 'INJURY']).size().unstack(fill_value=0)\n",
    "combination_counts['P(INJURY = yes)'] = combination_counts['yes'] / (combination_counts['yes'] + combination_counts['no'])\n",
    "print(\"Part b(ii):\")\n",
    "print(combination_counts[['no', 'yes', 'P(INJURY = yes)']])\n",
    "print()\n",
    "\n",
    "#b(iii)\n",
    "combination_counts['Prediction'] = combination_counts['P(INJURY = yes)'].apply(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "print(\"Part b(iii):\")\n",
    "print(combination_counts[['P(INJURY = yes)', 'Prediction']])\n",
    "print()\n",
    "\n",
    "#b(iv)\n",
    "total_records = len(subset)\n",
    "p_injury_yes = sum(subset['INJURY'] == 'yes') / total_records\n",
    "p_weather_1_given_injury_yes = sum((subset['WEATHER_R'] == 1) & (subset['INJURY'] == 'yes')) / sum(subset['INJURY'] == 'yes')\n",
    "p_traf_con_1_given_injury_yes = sum((subset['TRAF_CON_R'] == 1) & (subset['INJURY'] == 'yes')) / sum(subset['INJURY'] == 'yes')\n",
    "p_weather_1 = sum(subset['WEATHER_R'] == 1) / total_records\n",
    "p_traf_con_1 = sum(subset['TRAF_CON_R'] == 1) / total_records\n",
    "naive_bayes_prob = (p_weather_1_given_injury_yes * p_traf_con_1_given_injury_yes * p_injury_yes) / (p_weather_1 * p_traf_con_1)\n",
    "print(f\"Part b(iv): {naive_bayes_prob:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "#c(i)\n",
    "data['INJURY'] = data['MAX_SEV_IR'].apply(lambda x: 'yes' if x in [1, 2] else 'no')\n",
    "predictors = ['WRK_ZONE', 'WKDY_I_R', 'INT_HWY', 'PED_ACC_R', 'SPD_LIM', 'TRAF_CON_R', 'VEH_INVL', 'WEATHER_R']\n",
    "outcome = 'INJURY'\n",
    "X = pd.get_dummies(data[predictors])\n",
    "y = data[outcome].astype('category')\n",
    "\n",
    "#c(ii)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_val_pred = nb_model.predict(X_val)\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "print(\"Part c(ii)):\")\n",
    "print(conf_matrix)\n",
    "print()\n",
    "\n",
    "#c(iii)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "error_rate = 1 - accuracy\n",
    "print(f\"Part c(iii): Overall error rate for the validation set: {error_rate:.2f}\")\n",
    "print()\n",
    "\n",
    "#c(iv)\n",
    "naive_prediction = y_val.mode()[0]\n",
    "naive_error_rate = (y_val != naive_prediction).mean()\n",
    "print(f\"Part c(iv): Naive error rate: {naive_error_rate:.2f}\")\n",
    "percent_improvement = ((naive_error_rate - error_rate) / naive_error_rate) * 100\n",
    "print(f\"Percent improvement relative to the naive rule: {percent_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f065521-7647-4ee9-9ebb-98277f68896f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
